% !TeX program = xelatex
\documentclass[12pt,oneside]{book}

\usepackage{fontspec}
\usepackage{setspace}
\usepackage{xcolor}
\usepackage{titlesec}
\usepackage{titletoc}
\usepackage{multicol}
\usepackage{mathptmx}
\usepackage{tocloft} % Required for customizing the table of contents
\usepackage{lipsum} % for dummy text
\usepackage{ragged2e}
\usepackage{arabtex}
\usepackage{utf8}
\setcode{utf8}
\usepackage[nodayofweek]{datetime}
\usepackage{polyglossia}
\usepackage[
    left=12mm,
    right=12mm,
    bottom=20mm
]{geometry}
\geometry{a5paper}

\fontsize{8pt}{8pt}\selectfont

% \renewcommand{\cftsecleader}{\cftdotfill{\cftdotsep}} % Adds dots between section titles and page numbers


\setmainfont[Script=Arabic,Mapping=arabicdigits]{NoorNazanin}
\newfontfamily\arabicfont[Script=Arabic,Mapping=arabicdigits]{NoorNazanin}

\setmainlanguage{persian}
\setotherlanguage{english}
\setdefaultlanguage{persian}

\titleformat{\chapter}[display]
{\normalfont\LARGE\bfseries}{\chaptertitlename\ \thechapter}{20pt}{\Huge}
\titlespacing*{\chapter}{0pt}{-30pt}{20pt}

\titleformat{\section}
{\normalfont\Large\bfseries}{\thesection}{1em}{}

\dottedcontents{chapter}[1.5em]{\bfseries}{1.5em}{1pc}
\dottedcontents{section}[3.8em]{}{2.2em}{1pc}

\setlength\parskip{0.3em}

% Set line spacing to 1.6 (one-and-a-half spacing)
\setstretch{1.4}


\newdateformat{mydate}{\twodigit{\THEDAY}{ }\shortmonthname[\THEMONTH], \THEYEAR}


\begin{document}

    \frontmatter

    \begin{titlepage}
        \begin{center}
            \vspace*{1cm}

            {\huge \textbf{رفتار واقعی هوش‌مصنوعی برای دانشمندان داده}}

            \vspace{0.5cm}


            \LARGE انتشارات محمد رحیمی

            \large{\today}

        \end{center}
    \end{titlepage}

    \tableofcontents

    \newpage

    \section*{تشکر نامه}
    \addcontentsline{toc}{section}{تشکر نامه}
    \begin{spacing}{1.5}
        مایلم از مشارکت کنندگان زیر برای کمک‌های عالی و متنوعشان در این کتاب تشکر کنیم: پیتر هرشوک (اخلاق بودایی)، جان هکر رایت (اخلاق فضیلت)، ساموئل جی لوین و دانیل سینکلر (اخلاق یهودی)، کالین مارشال (اخلاق دئونتولوژیک)، جوی میلر و آندریا سالیوان کلارک (اخلاق بومی) و جان مورانگی (اخلاق آفریقایی).
        هدف ما ترسیم تصویری اخلاقی است که تا حد امکان منتوع و جذاب باشد.
        بدون کمک این عزیزان خردمند، توانستیم این کتاب را ایجاد کنیم!
    \end{spacing}

    \newpage

    \section*{فهرست همکاران و مشارکت کنندگان}
    \addcontentsline{toc}{section}{فهرست همکاران و مشارکت کنندگان}

    \begin{multicols}{2} % Start the two-column layout
        \begin{flushright}
            \begin{Large}
                \textbf{همکاران:}
            \end{Large}
        \end{flushright}

        \begin{flushright}
            \begin{normalsize}
                \textbf{پیتر سینگر}
            \end{normalsize}
            \\
            مرکز دانشگاهی برای ارزش های انسانی دانشگاه پرینستون
        \end{flushright}

        \begin{flushright}
            \begin{normalsize}
                \textbf{ییپ فای تسه}
            \end{normalsize}
            \\
            مرکز دانشگاهی برای ارزش های انسانی دانشگاه پرینستون
        \end{flushright}

        \begin{flushright}
            \begin{normalsize}
                \textbf{سامول جی لوین}
            \end{normalsize}
            \\
            مرکز حقوقی تورو
        \end{flushright}

        \begin{flushright}
            \begin{normalsize}
                \textbf{کولین مارشال}
            \end{normalsize}
            \\
            گروه فلسفه دانشگاه واشنگتن
        \end{flushright}

        \begin{flushright}
            \begin{normalsize}
                \textbf{جویی میلر}
            \end{normalsize}
            \\
            گروه فلسفه دانشگاه وست چستر
        \end{flushright}

        \begin{flushright}
            \begin{normalsize}
                \textbf{جان مورونگی}
            \end{normalsize}
            \\
            گروه فلسفه دانشگاه وست چستر
        \end{flushright}

        \begin{flushright}
            \begin{Large}
                \textbf{مشارکت کنندگان:}
            \end{Large}
        \end{flushright}

        \begin{flushright}
            \begin{normalsize}
                \textbf{جان هکر رایت}
            \end{normalsize}
            \\
            گروه فلسفه دانشگاه گوئلف
        \end{flushright}

        \begin{flushright}
            \begin{normalsize}
                \textbf{دنیل سینکلر}
            \end{normalsize}
            \\
            دانشکده حقوق دانشگاه فوردهام
        \end{flushright}

        \begin{flushright}
            \begin{normalsize}
                \textbf{پیتر دی هرشوک}
            \end{normalsize}
            \\
            مرکز شرقی-غربی
        \end{flushright}

        \begin{flushright}
            \begin{normalsize}
                \textbf{آندریا سالیوان کلارک}
            \end{normalsize}
            \\
            گروه فلسفه دانشگاه ویندزور
        \end{flushright}

    \end{multicols}

    \mainmatter


    \chapter{مقدمه: ماشین‌های اخلاقی}


    \section{ماشین‌های اخلاقی}

    این کتاب، برای دانشمنداد داده و افراد علاقه‌مند به این حوزه است؛ که در برخی جهات آن دچار تردید شده‌اند.
    یا به طور خلاصه، راه درست و غلط استفاده از دیتا را به افراد نشان دهد و از استفاده‌ی غیراخلاقی آن جلوگیری کند.

    به نظر می‌رسد که اهمیت علم داده در زندگی روزمره بسیار کم است!
    این امر باعث می‌شود که مردم عادی حتی در درک کردن این فناوری قدرتمند، کاملا ناتوان باشند؛ چه رسد به شکل‌دهی یا اداره‌ی آن!
    از طرفی خیلی از دانشمندانی که در این زمینه مشغول فعالیت هستند، نه زمان کافی برای کسب معلومات اخلاقی را دارند و نه منابع کافی برای اینکه ذهن خود را در گیر اهمیت اخلاق در این زمینه کنند.
    در صورتی که این فناوری می‌تواند تأثیرات اخلاقی زیادی را بر جامعه وارد کند.
    این کتاب در جهت کاهش این کمبودها نوشته‌شده است تا چراغ راهی باشد برای کسانی که به اخلاق در این حوزه اهمیت می‌دهند.
    برای این ایده که «دانشمندان باید اخلاق را بیاموزند»، تفکراتی مانند «شما نمی‌توانید چیزی در مورد اخلاق به کسی بیاموزید، مردم آن را میسازند» وجود دارد.
    البته قسمتی از آن درست است، مردم یک جامعه، اخلاق را می‌سازند.

    امروزه ما با یک پدیده‌ی بسیار قدرتمند و البته بسیار پر خطر به نام «علم داده» روبرو هستیم؛ بنابراین، باید اخلاقیات و ضوابط این حوزه به صورت گسترده آموزش داده شود.

    برای اینکه این کتاب تا حد امکان مفید و دوستانه واقع شود، سعی کردیم مطالب را با لحنی ساده بیان کنیم.
    در این کتاب، ۷ مثال واقعی که استفاده نادرست از علم داده را نشان می‌دهند، بیان می‌کنیم.
    ما همچنین با چندین دانشمند برجسته‌ی اخلاق تماس گرفتیم تا در هر مورد نظراتشان را بپرسیم.
    همچنین برای ارائه‌ی طیف وسیع رفتارها و اخلاقیات انسانی، از سه دیدگاه غرب نسبت به اخلاق، فراتر رفتیم، سه رویکرد غرب عبارتند از: نتیجه‌گرایی(فایده گرایی)، دین شناسی و رفتار با تقوا.
    رویکردهایی که به طور اضافی بررسی کردیم: بودایی، یهودی، بومی و آفریقایی.
    هر یک از این رفتارها و رویکردها، می‌توانند زاویه‌ی دید متنوعی را ارائه کنند که ممکن است به آن فکر نکرده باشیم.
    هدف ما این است که درک کاملی از هر رویکرد ارائه دهیم، یک جعبه ابزار کامل برای روبرویی با چالش‌های آینده.

    همانطور که می‌دانیم، یک مشکل خاص، می‌تواند با زوایای دید متفاوت (رویکردهای اخلاقی متفاوت که اشاره کردیم)، به طور مختلف تحلیل و بررسی شود.
    توانایی تحلیل معضل از دیدگاه‌های مختلف، لازمه‌ی «تفکر انتقادی» است.
    امیدوارم این کتاب دیدگاه گسترده‌ای را در اختیار خواننده قرار دهد!

    \newpage

    \section{علم داده چیست؟}
    \paragraph{}
    علم داده، اصولی است برای استخراج دیتاهای غیر بدیهی و الگوها از مجموعه دیتاهای بزرگ.
    از طرفی هوش مصنوعی را می‌توان هر گونه پردازش اطلاعات که کارکرد روانی را انجام می‌دهد، اطلاق کرد.
    مثلا پیش‌بینی، تداعی کردن، تخیل کردن، برنامه‌ریزی و به طور کلی، هر پردازشی که تا کنون موجودات زنده قادر به انجام آن بودند.

    ماشین لرنینگ ،(ML) زیرمجموعه‌ای از علم داده و بخش رو به رشدی از این زمینه است.
    بر خلاف ،GOFAI ماشین لرنینگ (ML) شکلی از هوش مصنوعی است که از رویکردهای آماری برای یافتن الگوها در دنیا (که بهم ریخته است) استفاده می‌کند.
    در خیلی جهات، ML پاسخی برای شکست‌های زودهنگام هوش مصنوعی سمبلیک (GOFAI) در بیرون از فضای آزمایشگاهی بود، به دلیل اینکه GOFAI قادر به پردازش پیچیدگی دنیای واقعی نبود.

    الگوریتم‌های ،ML با لایه‌های موازی اطلاعاتی که ارائه می‌شوند، آموزش داده می‌شوند و می‌توانند به روش‌هایی بیاموزند که نظارت نشده و نسبتا مرموز هستند!
    خیلی شبیه عملکرد مغز ما (از یک روش یا تابع استفاده می‌کند و آن را بر روی مجموعه‌ای از دیتا اعمال می‌کند).
    مانند تابعی که ایمیل‌های به درد نخور (هرزنامه) را شناسایی می‌کند؛ این تابع بر روی مجموعه‌ای از ایمیل‌ها اعمال می‌شود یا مشخص شود که کدام ایمیل به درد نخور است.

    ویژگی‌های هرزنامه‌ها و غیر هرزنامه‌ها قبلا توسط انسان‌هایی که تفاوت را می‌دانند، برای الگوریتم برچسب گذاری می‌شود.
    از طرف دیگر، یادگیری بدون نظارت، شامل هیچ برچسب‌زنی‌ای نمی‌شود و ما نمی‌دانیم که دنبال چه فاکتورهایی هستیم!
    این الگوریتم در ابتدا مجموعه‌ای دیتا دریافت می‌کند و بررسی می‌کند که کدام ویژگی‌ها مرتبط هستند.
    برای مثال، یک الگوریتم بدون نظارت، ممکن است که به تصاویر متعددی از سگ نگاه کند و تعیین کند چه ویژگی‌هایی جوهره‌ی «سگ بودن» را به وجود می‌آورد.
    زمانی هم که با یک تصویر جدید روبرو می‌شود، می‌تواند تصمیم بگیرد که سگ است یا خیر.

    امروزه ابزارهای علم داده خیلی کاربرپسندتر شدند و تازه‌واردان و حتی افرادی که آموزش کمی دارند، به راحتی می‌توانند وارد این زمینه شوند.
    این به این معنی است که هیچ وقت انجام کار با نتایج بد در این زمینه، به این آسانی نبوده است!
    بنابراین عواقب پروژه‌هایی بد، باید توسط کسانی که وظیفه‌ی طراحی یا اجرای آن را دارند، پیش‌بینی شود.

    همانطور که کِلِهِر (Kelleher) توضیح می‌دهد: «دیتا یا داده»، عنصری است که از دنیای واقعی انتزاع شده است و «اطلاعات»، داده‌هایی هستند که سازماندهی شدند تا مفید واقع شوند و «دانش» درک دقیق اطلاعاتی هست که داده‌ها به ما می‌دهند.
    اما با ارزش‌تر از همه، خرد است؛ که زمانی رخ می‌دهد که دانش را برای هدف خوب به کار ببریم.
    هدف ما این است که به خوانندگان خود کمک کنیم تا این خرد را توسعه دهند؛ که فکر می‌کنیم در قلب اخلاق علم داده قرار دارد.

    بنابراین، اخلاق فقط بخشی از انجام خوب علم داده است.
    این یعنی، یک مشکل در دنیای واقعی، بسیار فراتر از جنبه‌های فنی آن است و البته اینکه یک سیستم چگونه قرار است زندگی افراد را تحت تاثیر قرار دهد نیز، اهمیت دارد!

    \section{موارد مطالعاتی}

    \subsection{مورد اول اخلاق تحقیق و روش علمی}
    \paragraph{}
    مورد مطالعاتی اول، خواننده را با مفاهیمی مانند تکثیرپذیری، دقت و اعتبار آشنا می‌کند.
    بسیاری از این بحث‌ها بر اساس تلاش‌های اخیر در روانشناسی و همچنین علوم اجتماعی و پزشکی استوار شده است تا به واقعیتی که قسمت قابل توجهی از نتایج منتشر شده قابل تکثیر یا اعتبارسنجی نیستند، پاسخ دهند.

    این مورد، سوءرفتار تحقیقاتی در آزمایشگاه غذایی کورنل Cornell Food and Brand Lab به وسیله‌ی برایان وانسینک Brian Wansink را شرح می‌دهد.
    مشخص شد که او برای نتایج از چندین روش غیر علمی و البته غیر اخلاقی استفاده کرده است.
    روش‌هایی از جمله: cherry picking (برای علنی کردن نتایجی که مثبت بودند)، روش HAEKing (فرضیه سازی پس از مشخص شدن نتایج تجربی) و روش p-hacking (دستکاری داده ها برای به دست آوردن یک نتیجه آماری معنی دار)

    آقایان «سینگر» و «فای تسه» تفسیری بر رفتار «وانیسنک» از دیدگاه فایده‌گرایی ارائه می‌دهند.
    این دو بر اهمیت راست بودن نتایج علمی که دیگران به آن تکیه می‌کنند، تأکید دارند.
    کسانی که این وظیفه را به عهده گرفته‌اند تا شواهد علمی و تجربی‌ای را که دیگران از آن استفاده می‌کنند، ارائه دهند، درواقع بار سنگینی را بر دوش دارند.
    آنها باید این کار با به بهترین نحو ممکن انجام دهند.

    \subsection{مدل‌های ماشین در دادگاه}
    \paragraph{}
    الگوریتم‌های \textenglish{\textbf{ML}} ، در چندین پرونده‌ی جنایی مورد استفاده قرار گرفت و البته اشکال اخلاقی را نیز به بار آورد.
    حتی بهترین مدل‌های تائید شده نیز در زمینه‌های اجتماعی مختلف نیز عملکر متفاوتی دارند.
    حتی مدل‌های عالی نیز که توسط انسان استفاده می‌شوند، می‌توانند عواقب ناخواسته‌ای را شامل: «تبعیض»، «تعصب» و «سوءاستفاده‌ی عمدی» به بار بیاورند.

    استفاده از مدل \textenglish{\textbf{Markov chain Monte Carlo (MCMC)}} منجر به معضل اخلاقی می‌شود.
    زیرا این مدل نمی‌تواند به طور کامل تکرار شود و درنتیجه شواهد تولید شده توسط آن نیز قابل تکرار نیست.

    این مسائل از طریق یک مطالعه درباره الگوریتم‌های ترکیب \textenglish{\textbf{DNA}}  و نقش آن‌ها در محاکمه نادرستِ «اورال نیکولاس هیلاری» \textenglish{\textbf{(Oral Nicholas Hillary)}}  در قتل یک پسر جوان در پاتسدام، نیویورک، توضیح داده می‌شوند.
    در این مورد، تحقیقات پلیس و محاکمه شامل \textbf{عوامل قویی از تعصب شخصی و نژادی} علیه هیلاری بود، که یک مربی محبوب و موفق با ریشه‌های آفریقایی-کارائیبی بود.
    این موجب شد تفسیر بسیار تعصب‌آمیزی از شواهد DNA برای متهم ساخته شود.
    بازرسی شد که شواهد ناقص و غیرقابل اعتماد بوده و به درستی توسط دادگاه از پرونده حذف شده است، که در نتیجه به هیلاری تبرئه شد.

    «ساموئل جِی لووین» از دیدگاه اخلاق یهودی، استفاده از مدل‌های یادگیری ماشینی در سامانه عدالت کیفری را مورد بررسی قرار می‌دهد و به بررسی تنش‌ها (در واقع تناقض) بین جبر و اراده آزاد در اخلاق یهودی پرداخته است.

    ما همه عاملان اخلاقی هستیم و مسئول انتخاب‌های خودمان هستیم.
    اما اگر اعمال ما پیش از این تعیین شده باشند، آیا ما در حقیقت دیگران را برای تصمیماتی که نگرفته‌اند، قضاوت نمی‌کنیم؟ طوری دیگر بیان می‌کنم: اگر اعمال ما از پیش تعیین شده باشند، این به معنای آن است که پیش‌تر مشخص شده‌اند و نشان می‌دهد که ما کنترلی بر روی آن‌ها نداریم.\     جمله‌ای که شما ارائه داده‌اید، سؤالی را مطرح می‌کند که آیا عادلانه است که افراد را برای تصمیماتی که آن‌ها جز گزینه‌هایی که می‌توانستند انتخاب کنند، قضاوت کنیم؟ به عبارت دیگر، اگر انتخاب‌های یک شخص از پیش تعیین شده باشد و او اراده آزادی نداشته باشد، آیا منصفانه است که او را برای آن تصمیمات مسئول دانسته و قضاوت کنیم؟

    این را می‌توان در استفاده گسترده از مدل‌های ماشینی برای پیش‌بینی میزان تکرار جرم و احکام و تصمیم‌گیری برای دریافت وثیقه برای متهمان مشاهده کرد.
    بسیاری از قوانین جزایی ما مبتنی بر ایده هایی در مورد اختیار است که از یهودیت گرفته شده و از طریق ادیان ابراهیمی منتشر شده است.
    تنش بین جبرگرایی و اراده آزاد در بسیاری از تصمیم گیری ها در سیستم عدالت کیفری ما نفوذ می کند.
    در همین حال، کسانی که به‌جای عدالت به دنبال قدرت هستند، می‌توانند از فناوری‌های علمی به گونه‌ای سوء استفاده کنند که از مرزهای اخلاقی خارج شود.

    «کالین مارشال» اثبات‌های تولیدشده توسط مدل‌های ماشین را از دیدگاه اخلاق «دانتولوژیک» بررسی می‌کند، که به مدت طولانی نگران شناسایی و از بین بردن اشکالاتی از نوع ناعادلانه‌گرایی در تصمیم‌گیری اخلاقی بوده است که برخی افراد را نسبت به دیگران در مزیت قرار می‌دهد.
    تصمیمات اخلاقی باید آزمون همگانی را پشت سر بگذارند: اگر یک اقدام همگانی نباشد، به این معناست که همه انجام‌دهندگان در یک موقعیت مشابه، به احتمال زیاد یک انتخاب مشابه را انجام خواهند داد.
    این باید همه دانشمندان داده را تشویق کند که به تأثیرات مدل‌هایشان از دیدگاه افرادی که تحت تأثیر قرار می‌گیرند نگاهی بیندازند.
    این نیازمند این است که عاملان اخلاقی از دیدگاه خود، گاهی اوقات فایده‌گرایی، خارج شوند.
    اگر همه به این شیوه عمل کنند، سیستمی که ما می‌خواهیم در آن به طور غیرعادلانه توسط یک تحلیلگر جزئی یا یک الگوریتم تعصبی اتهام شویم، چگونه خواهد بود؟ سیستم‌هایی که شامل ناعدالتی غیرمشروع هستند، از نظر اخلاقی غیرمجاز هستند و باید استفاده نشوند.

    \subsection{رسانه‌های ساختگی و خشونت سیاسی}
    در این مورد، دو مثال را بررسی می‌کنیم:
    \paragraph{}
    ۱- مثال اول در مورد سخنرانی رئیس جمهور «گابن علی بونگو» \textenglish{\textbf{(Gabonese Ali Bongo)}} در شب سال نو سال ۲۰۱۹ است.
    این ویدئو برای فرونشاندن ترس‌ها در مورد بیماری اخیر «بونگو» طراحی شده بود.
    اما زمانی که این ویدئو به عنوان یک دیپ‌فیک \textenglish{\textbf{(deepfake)}} شناخته شده، تنش‌های سیاسی را برانگیخت.
    سربازان گارد جمهوری خواه، کودتای نافرجامی را در لیبرویل راه انداختند؛ به این دلیل که «بونگو» دیگر در رأس کار نیست و نمی‌توان به حزب حاکم اعتماد کرد.
    کودتا با خشونت سرکوب شد و منجر به کشته شدن دو سرباز و بازداشت خیلی‌ها شد.
    ولی بعدا مشخص شد که ویدئو کاملا واقعی بوده!
    در ویدئو به نظر می‌رسد که اثرات deepfake روی «بونگو» مشاهده می‌شود، ولی درواقع تاثیرات بعد از عمل باعث این موضوع شده بود!
    چشم‌های «بونگو» به طور غیر طبیعی در ویدئو مشاهده می‌شود که گمان deepfake را می‌رساند.

    \paragraph{}
    ۲- مثال دوم به «فیک های کم عمق» \textenglish{\textbf{(shallow fakes)}} علیه زنان در هند، به ویژه روزنامه نگاران و سیاستمدارانی که از حزب حاکم انتقاد می کنند، می پردازد.
    این رسانه‌های دستکاری شده شامل سایت‌های حراج جعلی هستند که مدعی «فروش» زنان هستند و آنها را در شرایط تحقیرآمیز جنسی «پورنوگرافی» به تصویر می‌کشند.
    خبرنگاران زن در هند متوجه شده‌اند که پورنوگرافی تقلبی می‌تواند باعث ویرانی روحی‌شان شود و زندگی حرفه‌ای آن‌ها را به پایان برساند فقط به این دلیل که در دسترس عموم قرار گرفته‌اند!
    و نه به این دلیل که کسی باور کند این عکس‌ها و ویدئوها "واقعی" هستند.



    \subsection{زیر بخش اول}

    این یک مثال است.


    \section{بخش دوم}

    این یک مثال است.

    \backmatter

\end{document}
