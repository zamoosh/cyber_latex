%! Author = zamoosh
%! Date = 6/13/23


\chapter{بدافزارهای ذهنی: الگوریتم‌ها و معماری انتخاب}
\label{ch:بدافزارهای ذهنی الگوریتم‌ها و معماری انتخاب}
\phantomsection

\begin{quote}
    ما نمی‌خواهیم از مردم بپرسیم که قرار است چه کاری انجام دهند.
    زیرا می‌دانیم که این امر چندان پیش‌بینی‌کننده نحوه اجرای یک تبلیغ نیست، زیرا افراد به مغز چپ خود می‌روند و بیش از حد شروع به فکر کردن می‌کنند.
    \\\\
    \textbf{کری کالینگ، مدیر بازاریابی در شرکت بازاریابی \textenglish{\textbf{«System 1 Group»}}}
    \newline
\end{quote}


{\setstretch{0.5}
\phantomsection
\section*{رسوایی داده های کمبریج آنالیتیکا}
\label{sec:رسوایی داده های کمبریج آنالیتیکا}
\addcontentsline{toc}{section}{رسوایی داده های کمبریج آنالیتیکا}{\protect\numberline{}}
رسوایی داده‌های کمبریج آنالیتیکا ریشه در سال 2010 داشت که \textenglish{\textbf{Facebook}} برنامه \\ \textenglish{\textbf{\mbox{Open Graph}}} خود را راه‌اندازی کرد. \textenglish{\textbf{Open Graph}} به توسعه دهندگان برنامه‌های شخص ثالث اجازه می‌دهد تا به اطلاعات شخصی کاربران \textenglish{\textbf{Facebook}} و همچنین همه‌ی داده‌های «دوستان» خود دسترسی داشته‌باشند. در سال 2013، «محقق دانشگاهی الکساندر کوگان»، در همکاری با شرکت بازاریابی و تجزیه و تحلیل داده‌ها، کمبریج آنالیتیکا، اپلیکیشنی به نام «این زندگی دیجیتال شماست» راه‌اندازی کرد. این اپلیکیشن از کاربران دعوت کرد تا در یک مسابقه شخصیت‌شناسی رایگان شرکت کنند و حدود 300000 کاربر \textenglish{\textbf{Facebook}} این کار را انجام‌دادند. این برنامه داده‌های مربوط به پروفایل‌های روان‌سنجی آن‌ها را از آزمون جمع‌آوری کرد (که پنج ویژگی شخصیتی بزرگ کاربران را اندازه‌گیری می‌کرد) اما همچنین به‌طور آزادانه داده‌های \textenglish{\textbf{Facebook}} را از همه‌ی دوستان آن‌ها جمع‌آوری کرد. کمبریج آنالیتیکا در تلاش بود تا مجموعه‌ای از رای‌دهندگان آمریکایی را تا حد امکان جمع‌آوری کند.
}

در سال 2015، اولین گزارش‌ها منتشر شد مبنی بر اینکه کمپین سیاسی تد کروز میلیون‌ها نفر از این پروفایل‌های روان‌سنجی را در تلاش برای کسب مزیت در انتخابش به مجلس سنای ایالات متحده تجزیه و تحلیل کرده است (افشاگری که کاملاً نامحبوب بود و منجر به تضمین‌هایی از سوی \textenglish{\textbf{Facebook}} و کمبریج آنالیتیکا که داده‌های مورد نظر حذف شده است).

با این حال، در سال 2018 اخبار منتشر شد مبنی بر اینکه داده‌های ده‌ها میلیون کاربر \textenglish{\textbf{Facebook}} (شاید به 87 میلیون نفر) توسط کمبریج آنالیتیکا جمع‌آوری‌شده و در انتخابات ریاست‌جمهوری آمریکا در سال 2016 توسط ستاد انتخاباتی دونالد ترامپ استفاده شده‌است.
بسیاری از این افراد تست شخصیت را انجام نداده بودند، اما از زمانی که یکی از دوستانشان شرکت کرده بود، محققان می‌توانستند آزادانه به داده‌های آن‌ها دسترسی داشته‌باشند.
سپس کمبریج آنالیتیکا داده‌های \textenglish{\textbf{Facebook}} را با سایر داده‌هایی که خریداری کرده بود و همچنین فهرست‌های انتخاباتی محلی ارجاع داد.
بنابراین، کمبریج آنالیتیکا توانست پرونده‌های گسترده‌ای را در مورد ده‌ها میلیون رای‌دهنده، از جمله ویژگی‌های جمعیتی، ویژگی‌های شخصیتی، شبکه‌های اجتماعی، تاریخچه خرید، لایک‌ها، عضویت در احزاب سیاسی و غیره جمع‌آوری کند.
«مک‌نامی» تخمین می‌زند که این پرونده‌ها در نهایت شامل حدود 13 درصد همه‌ی رای دهندگان واجد شرایط ایالات متحده بوده.

کمبریج آنالیتیکا از مشخصات رأی دهندگان خود برای کسب برتری در انتخاب دونالد ترامپ به عنوان رئیس جمهور ایالات متحده در سال 2016 و همچنین کمپین «خروج» رفراندوم برگزیت در بریتانیا استفاده کرد.
همانطور که \textenglish{\textbf{Cadwalladr}} توضیح می‌دهد، کمبریج آنالیتیکا از نتایج آزمایش و داده‌های \textenglish{\textbf{Facebook}} برای ساخت الگوریتمی استفاده کرد که می‌تواند پروفایل‌های فردی \textenglish{\textbf{Facebook}} را تجزیه و تحلیل کند و ویژگی های شخصیتی مرتبط با رفتار رأی‌گیری را تعیین کند.
این الگوریتم به‌ویژه مؤثر بود زیرا به دانشمندان داده اجازه می‌داد تا رأی‌دهندگان نوسان را شناسایی کنند و سپس آن‌ها را با تبلیغات و پیام‌های خاصی که به احتمال زیاد رأی آن‌ها را «تحریک» می‌کرد، هدف قرار دهند.
\newline
\newline


{\setstretch{0.5}
\phantomsection
\section*{معماری انتخابی و فناوری متقاعد کننده: "جعبه ای برای انسان مدرن"}
\label{sec:معماری انتخابی و فناوری متقاعد کننده: "جعبه ای برای انسان مدرن"}
\addcontentsline{toc}{section}{معماری انتخابی و فناوری متقاعد کننده: "جعبه ای برای انسان مدرن"}{\protect\numberline{}}
کمبریج آنالیتیکا از داده‌ها برای آموزش الگوریتم‌های توصیه و ترویج محتوای رسانه‌های اجتماعی «قادر به حرکت دادن افکار عمومی در مقیاس» استفاده‌کرد.
الگوریتم‌های کمبریج آنالیتیکا این کار را با دسته‌بندی خرد افراد در گروه‌هایی که با ویژگی‌های جمعیت‌شناختی، سیاسی و روان‌سنجی تعریف می‌شوند انجام می‌دهند: برای مثال، رای دهندگان زن محافظه کار اجتماعی در حومه‌های مرفهِ دی سی که فرزندانشان تحت تاثیر تعطیلی مدارس مرتبط با کووید قرار‌گرفته‌اند، رای دهندگان طبقه کارگر در کمربند زنگ زده که درازمدت کم کار هستند، بازنشستگان طبقه پایین از فلوریدا مرکزی که نگران افزایش هزینه‌های مراقبت‌های بهداشتی هستند.
هدف از این الگوریتم‌ها هدف قرار دادن «رای‌دهندگان نوسان» بسیار مورد علاقه است تا بتوانند رأی خود را در مناطق مهم میدان نبرد تحت‌تأثیر قرار‌دهند.
بیش از این، آن‌ها می‌توانند الگوریتم‌های خود را در زمان واقعی در گروه‌های متمرکز آموزش‌دهند و بهبود بخشند.
}

اگرچه \textenglish{\textbf{Facebook}} به دلیل نقض داده‌ها توسط کمیسیون تجارت فدرال 5 میلیارد دلار جریمه شد، خطرات آنچه به عنوان "فناوری متقاعد کننده" شناخته می‌شود بسیار فراتر از رسوایی داده‌های کمبریج آنالیتیکا است.
مربیان و روانشناسان برای سال‌ها نگرانی‌هایی را در مورد فناوری متقاعدکننده مطرح کرده‌اند، اما این تأثیر کمی بر صنایع بازاریابی مصرف‌کننده و سیاسی داشت.
این رسوایی بسیار بیشتر از نقض حریم خصوصی کاربران است.
همانطور که مک نامی بیان می‌کند، این در مورد این است که چگونه "داده‌های ما هوش‌مصنوعی را تغذیه می‌کند که هدف آن‌ها دستکاری توجه و رفتار کاربران بدون اطلاع یا تایید آن‌ها است".

در حالی که بازاریابی مبتنی بر گروه‌های جمعیتی سابقه طولانی دارد، این عمل با حجم عظیمی از داده‌های ایجاد شده توسط رسانه‌های اجتماعی افزایش یافته‌است.
به عنوان مثال، \textenglish{\textbf{Facebook}} گروه‌هایی به نام \textenglish{\textbf{"lookalikes"}} ایجاد کرده‌است که کاربران را به گروه‌هایی با پروفایل‌های مشابه طبقه‌بندی می‌کند تا به شرکت در هدف‌گیری خرد آن‌ها کمک کند.
«کریستوفر ویلی، دانشمند سابق داده که در کمبریج آنالیتیکا افشاگر شد»، اظهار می‌دارد که به کاربران محتوایی بر اساس گروه مشابه خود ارائه می‌شود که سایر کاربران نمی‌بینند.
این امر باعث ایجاد حباب‌های فیلتر شده و شکاف‌های اجتماعی را عمیق‌تر می‌کند.
او بیان می‌کند که «خط ظریفی بین الگوریتمی وجود دارد که شما را تعریف می‌کند تا نشان دهد واقعاً چه کسی هستید و الگوریتمی که شما را برای ایجاد یک پیش‌گویی خودشکوفایی از اینکه فکر می‌کند باید تبدیل شوید، تعریف می‌کند».

شبیه‌سازی‌ها و ریزهدف‌گذاری از قدرت علم‌داده برای درگیر‌شدن (هرچند بسیار مؤثرتر) در رویه‌ی قدیمی تبلیغات استفاده می‌کنند.
بازاریابان، برای شرکت‌های مصرف‌کننده و کمپین‌های سیاسی، به طور معمول محتوای اخلاقی و بسیار احساسی را ارائه می‌دهند که به سرعت در رسانه‌های اجتماعی پخش می‌شود.
در واقع، رسانه‌های اجتماعی و دیگر پلت‌فرم‌های آنلاین اکنون «منابع اولیه محرک‌های اخلاقی مرتبطی هستند که افراد در زندگی روزمره خود تجربه می‌کنند».
کسانی که از رسانه‌های اجتماعی برای تأثیرگذاری بر افکار عمومی استفاده می‌کنند، از یادگیری پاداش اجتماعی نیز استفاده می‌کنند (معمولاً به شکل «اشتراک‌گذاری»، «کلیک»، «لایک»، «فالوور» و دیگر اشکال تقویت‌کننده تعامل).
این رفتارها نه تنها بسیار پاداش دهنده هستند، بلکه می‌توانند توسط سیستم‌های یادگیری‌ماشین استخراج شوند تا رفتار آینده‌ی ما، دوستان و پیروان ما و گروه‌های مشابه ما را پیش‌بینی کنند.
فردی را که با محتوای آنلاین درگیر می‌شود مانند موش در جعبه اسکینر که اهرم پاداش را فشار می‌دهد تصور کردند و به این نتیجه رسیدند که رسانه‌های اجتماعی مانند "جعبه اسکینر برای انسان مدرن است".

مقایسه بین تعامل در رسانه‌های اجتماعی و یک موش آزمایشی در یک جعبه عمیق است.
در سال 2014، مطالعه ای با همکاری \textenglish{\textbf{Facebook}} و دانشگاه کرنل منتشر شد)این آزمایش شامل آزمایشگاه غذا و برند نیست، بلکه دپارتمان علوم ارتباطات و اطلاعات بود(.
محققان محتوای احساسی پست‌هایی را که کاربران \textenglish{\textbf{Facebook}} در فیدهای خبری خود دریافت می‌کردند، دستکاری کردند، به‌ویژه از افرادی که به آن‌ها اعتماد داشتند، مانند دوستان و کسانی که دنبال می‌کردند.
محققان می‌خواستند ببینند آیا محتوای عاطفی مثبت در مقابل منفی بر خلق و خوی پست‌های بعدی کاربران تأثیر می‌گذارد یا خیر (به عنوان مثال، آیا شواهدی از «سرایت عاطفی» در رسانه‌های اجتماعی وجود دارد یا خیر).
وجود داشت، اما این مهم‌ترین جنبه مطالعه نبود.
به شرکت کنندگان اطلاع داده‌نشد که از آن‌ها به عنوان موضوع تحقیق استفاده می‌شود.
در واقع، رضایت آن‌ها برای شرکت در تحقیقات تجربی هرگز دریافت‌نشد.
از آنجایی که داده‌ها توسط \textenglish{\textbf{Facebook}} جمع‌آوری شده‌بود، محققان حتی به دنبال تأیید هیئت بررسی اخلاق پژوهشی کورنل نبودند.
معلوم نیست اگر می‌گرفتند تایید می‌شدند.

هنگامی که اخبار عدم‌رضایت منتشر شد، واکنش‌های منفی علیه این مطالعه وجود داشت.
اصل اصلی اخلاق تحقیق مستلزم کسب رضایت آگاهانه از شرکت کنندگان در تحقیق است.
این اصل در زمینه اخلاق پزشکی ایجاد شد (به \hyperref[sec:کادر 1.8]{\mbox{کادر 1.8}} مراجعه کنید) اما از آن زمان به تمام زمینه‌های تحقیقات آکادمیک مربوط به موضوعات انسانی گسترش یافته است.
بسیاری از متخصصان اخلاق زیستی استدلال می‌کردند که این تحقیق «به‌طور فاحش» هیچ‌یک از اصول قانون یا اخلاقی را نقض نمی‌کند، و اگر این کار را انجام می‌داد، به این معناست که شیوه‌های استاندارد \textenglish{\textbf{Facebook}} نیز از نظر اخلاقی مشکوک هستند.
«کاترین فلیک» با این استدلال پاسخ داد که اصول اخلاقی شرکت‌هایی که به طور معمول کاربران را بدون اطلاع یا رضایت آن‌ها در معرض دستکاری آزمایشی و آزمایشی قرار می‌دهند، دقیقاً موضوع مورد بحث است.

در حالی که دانشمند اصلی در مطالعه سرایت عاطفی عذرخواهی کرد، این نقض اخلاقی رسوایی کمبریج آنالیتیکا را که به زودی دنبال می‌شود، پیش‌بینی کرد.
اساتید برجسته در دانشگاه‌های معتبری مانند کمبریج و هاروارد از توسعه الگوریتم کمبریج آنالیتیکا اطلاع داشتند و آن را هیجان‌انگیز و نوآورانه می‌دانستند.
به نظر می‌رسد که بحثی در مورد اخلاق تحقیق وجود نداشته‌است.
همانطور که «ویلی» می‌گوید، «با توجه به اینکه دانشمندان دانشگاه‌های برجسته جهان به من می‌گفتند در آستانه «انقلاب‌سازی» علوم اجتماعی هستیم، من حریص شده‌بودم و جنبه‌های تاریک کاری را که انجام می‌دادیم نادیده می‌گرفتم».


% ======================================== کادر 8.1
\begin{tcolorbox}[colback=gray!10,colframe=black,breakable]

    \phantomsection
    \section*{کادر 1.8}
    \label{sec:کادر 1.8}
    \begin{Large}
        \textbf{\mbox{اصول قانون نورنبرگ}}
    \end{Large}
    \newline
    \newline
    اصول نورنبرگ در مورد آزمایش انسان عبارتند از:

    \begin{description}[leftmargin=0.5cm,style=nextline]
        \item[۱] رضایت داوطلبانه سوژه انسانی کاملاً ضروری است.
        \item[۲] آزمایش باید به گونه ای باشد که نتایج مثمر ثمری برای صلاح جامعه داشته باشد، غیرقابل تهیه با روش ها یا وسایل مطالعه دیگر باشد و ماهیت تصادفی و غیر ضروری نداشته باشد.
        \item[۳] آزمایش باید به گونه ای طراحی و بر اساس نتایج آزمایش بر روی حیوانات و آگاهی از تاریخچه طبیعی بیماری یا سایر مشکلات مورد مطالعه باشد که نتایج پیش بینی شده انجام آزمایش را توجیه کند.
        \item[۴] آزمایش باید به گونه ای انجام شود که از همه رنج ها و آسیب های جسمی و روحی غیر ضروری جلوگیری شود.
        \newpage
        \item[۵] هیچ آزمایشی نباید در جایی انجام شود که دلیل پیشینی وجود داشته باشد که باور شود مرگ یا آسیب ناتوان کننده رخ خواهد داد.
        به جز، شاید، در آزمایش هایی که پزشکان تجربی نیز به عنوان سوژه خدمت می کنند.
        \item[۶] درجه خطری که باید متحمل شود هرگز نباید بیشتر از میزانی باشد که با اهمیت انسان دوستانه مشکلی که باید توسط آزمایش حل شود تعیین می شود.
        \item[۷] باید آماده‌سازی مناسب و امکانات کافی برای محافظت از آزمودنی آزمایشی در برابر احتمالات دوردست آسیب، ناتوانی یا مرگ فراهم شود.
        \item[۸] آزمایش فقط باید توسط افراد واجد شرایط علمی انجام شود.
        بالاترین درجه مهارت و مراقبت باید در تمام مراحل آزمایش کسانی که آزمایش را انجام می دهند یا درگیر آن هستند، لازم باشد.
        \item[۹] در طول آزمایش، آزمودنی انسانی باید آزاد باشد که آزمایش را به پایان برساند، اگر به وضعیت جسمی یا روانی رسیده باشد که ادامه آزمایش به نظر او غیرممکن است.
        \item[۱۰] در طول آزمایش، دانشمند مسئول باید آمادگی داشته باشد که آزمایش را در هر مرحله خاتمه دهد، اگر احتمالاً دلایلی برای باور داشته باشد، به اعمال حسن‌نیت، مهارت برتر و قضاوت دقیق که از او مستلزم ادامه است.
        این آزمایش احتمالاً منجر به آسیب، ناتوانی یا مرگ آزمودنی می شود.
    \end{description}
\end{tcolorbox}

فناوری متقاعدکننده بخشی از حوزه وسیع‌تر «معماری انتخاب» است.
یک معمار انتخابی «زمینه‌ای را که مردم در آن تصمیم می‌گیرند» سازمان‌دهی می‌کند.
چیزی به نام زمینه‌ی خنثی وجود ندارد: همه‌ی شرایط حداقل مقداری فشار برای تصمیم‌گیری به یک روش یا روش دیگر اعمال می‌کنند.
همه‌ی ما در یک حوزه‌ی اجتماعی پیچیده و پویا تازه‌کار هستیم که توسط متخصصان، متخصصان و الگوریتم‌های بسیار آموزش دیده پر شده‌است (که هدف ترکیبی آن عمدتاً فروش چیزی به ما یا تشویق ما برای پذیرش یک عقیده یا نامزد سیاسی بر دیگری است).
الگوهای توصیه‌ای از سوگیری‌های شناختی و استعدادهای ناخودآگاه بهره می‌برند و از «افراد پرمشغله‌ای که سعی می‌کنند در دنیای پیچیده‌ای که در آن نمی‌توانند در مورد هر انتخابی که باید عمیقاً و طولانی فکر می‌کنند، کنار بیایند» سود می‌برند.

بازاریابان می‌توانند با تجزیه و تحلیل حالات چهره‌ی ما در زمان واقعی، به واکنش‌های احساسی (ناخودآگاه و چند ثانیه‌ای ما نگاه کنند).
سپس آن‌ها می‌توانند از این داده‌ها برای هدف قرار دادن پیام‌ها و تأثیرگذاری بر رای دادن و رفتار مصرف‌کننده استفاده‌کنند.
این از چیزی که «دانیل کانمن» روانشناس آن را تفکر «سیستم 1» می‌نامد بهره می‌برد (تفکر خودکار، احساسی و ناخودآگاه ما که تفکر منطقی و عمدی «سیستم 2» را دور می‌زند).
به این ترتیب، شرکت‌های بازاریابی مانند کمبریج آنالیتیکا می‌توانند اطمینان حاصل کنند که انتخاب‌های ما خودکار هستند، به راحتی توسط محتوای احساسی و اخلاقی دستکاری می‌شوند، و طوری طراحی شده‌اند که مطمئن شوند هیچ زمانی را صرف «فکر کردن بیش از حد» نمی‌کنیم!!!
\newline
\newline


{\setstretch{0.5}
\phantomsection
\section*{سیاستمداران «محبوب»، فعالیت «غیر اصیل» و اثر متیو}
\label{sec:سیاستمداران «محبوب»، فعالیت «غیر اصیل» و اثر متیو}
\addcontentsline{toc}{section}{سیاستمداران «محبوب»، فعالیت «غیر اصیل» و اثر متیو}{\protect\numberline{}}
معماری انتخابی و فناوری متقاعدکننده توسط سیاستمداران و کمپین‌های سیاسی در سراسر جهان، از جمله توسط چندین رژیم استبدادی، بسیار مورد استفاده قرار گرفته‌است.
«خوان اورلاندو هرناندز، رئیس جمهور هندوراس»، با ایجاد صفحات و پروفایل‌های کاربری جعلی، صدها هزار دنبال‌کننده و لایک در \textenglish{\textbf{Facebook}} جمع‌آوری کرد.
همه‌ی این صفحات توسط همان شخصی اداره می‌شد که حساب‌های شبکه‌های‌اجتماعی خود «هرناندز» را مدیریت می‌کرد.
هرناندز یک حاکم ملی‌گرا و خودکامه است که از کودتای 2009 در هندوراس حمایت کرد.
او متهم شده‌است که با استفاده از تاکتیک‌هایی مشابه آنچه روسیه در انتخابات ۲۰۱۶ آمریکا به کار گرفته است، پیروزی خود در انتخابات ۲۰۱۷ را دستکاری کرده است.
}

«سوفی ژانگ»، دانشمند داده در \textenglish{\textbf{Facebook}} که به افشاگر تبدیل شد، یادداشتی 6600 کلمه ای برای افشای این کلاهبرداری نوشت.
کار او مبارزه با مشارکت جعلی از این نوع در \textenglish{\textbf{Facebook}} بود.
او توضیح می‌دهد که "مدیر می‌تواند با نشستن پشت صفحه رایانه، پستی در مورد اینکه هرناندز چقدر خوب کارش را انجام می‌دهد در صفحه \textenglish{\textbf{Facebook}} رئیس‌جمهور منتشر کند، سپس از صدها صفحه‌ی ساختگی خود برای محبوب نشان‌دادن پست استفاده کند" این (معادل یک اتوبوس ساختگی از افراد برای سخنرانی به صورت دیجیتالی) است.
(نوعی فعالیت غیراصیل که به نام «آستروتورفینگ» نیز شناخته می شود).

این نوع تعامل جعلی که در استانداردهای اجتماعی \textenglish{\textbf{Facebook}} به عنوان «رفتار غیراصیل هماهنگ» شناخته می‌شود، از «اثر متیو» استفاده می‌کند.
این به تمایل شخصی که دارای مزیت اولیه در یک سیستم است برای انباشت بیشتر در طول زمان اشاره دارد.
این نام از انجیل به روایت متی آمده است، که می‌گوید: "زیرا به کسی که دارد، بیشتر داده می‌شود و فراوانی خواهد داشت، اما از کسی که ندارد، حتی آنچه دارد گرفته می‌شود".

اثرات «مَتیو» گاهی اوقات سودمند است، اما اغلب باعث بی‌عدالتی می‌شود.
مشخص شده‌است که آن‌ها نقش کلیدی در حفظ و گسترش اقشار اقتصادی و اجتماعی از همه نوع دارند.
از آنجایی که همه سیستم‌های پیچیده پویا هستند، گاهی اوقات اثر معکوس رخ می‌دهد (هر چند وقت یک‌بار فقرا ثروتمندتر می‌شوند) اما این نادرتر است و اثرات ضعیف‌تر هستند.
این حلقه‌های بازخورد بخشی از بسیاری از سیستم‌های طبیعی و اکولوژیکی و گونه‌های زنده هستند.
در سراسر جهان طبیعی، به نظر می‌رسد که ثروتمندان تمایل (منظور میل و خواست نیست) آشکاری به ثروتمند شدن و فقرا به فقیرتر شدن دارند.
سیاستمدارانی که لایک‌ها و فالوورهای زیادی دارند، در شبکه‌های اجتماعی مشارکت بیشتری دارند و آن‌هایی که تعداد کمتری دارند، کمتر.

تیم ارزیابی تهدیدات \textenglish{\textbf{Facebook}}، یافته‌های ژانگ مبنی بر اینکه رئیس‌جمهور هندوراس درگیر یک فعالیت غیراصیل هماهنگ شده بود را تأیید کرد.
یک گزارش داخلی از \textenglish{\textbf{Facebook}} بیان کرد که مبارزات انتخاباتی او "به طور مداوم یک رئیس جمهور غیرقانونی احتمالی را در یک \textenglish{\textbf{ARC}} [کشور در معرض خطر] تقویت کرده است" و این احتمالاً "تأثیر \textenglish{\textbf{IRL}} [در زندگی واقعی] داشته است".
نزدیک به 1500 صفحه و صدها حساب تا جولای (ژانویه) 2019 حذف شدند!

حذف‌ها کمی تأثیر بلندمدت داشتند.
وقتی حساب‌ها و صفحات جعلی حذف می‌شوند، حساب‌های جدید روز بعد دوباره بالا می‌روند.
هرناندز تنها رهبر خودکامه‌ای نبود که از اثر متیو در کمپین‌های رسانه‌های اجتماعی خود استفاده می‌کرد.
ژانگ بیان می‌کند که فعالیت‌های غیراصولی مشابه توسط شبکه‌هایی در کشورهای سراسر جهان از جمله افغانستان، آلبانی، آذربایجان، بولیوی، جمهوری دومینیکن، اکوادور، السالوادور، هند، اندونزی، عراق، ایتالیا، مکزیک، مغولستان، پاراگوئه، فیلیپین، لهستان، کره جنوبی، تایوان، تونس، ترکیه و اوکراین به کار گرفته‌شده‌است.

فعالیت غیرواقعی آذربایجان به‌ویژه به دلیل سابقه ضعیف حقوق بشر و تمایل دولت به استفاده از تحریم‌های اقتدارگرایانه و خشونت برای سرکوب روزنامه‌نگاران و منتقدان دولت و محدود کردن آزادی‌های اینترنتی و دسترسی به اطلاعات، نگران‌کننده است.
«وانگ» گزارش می‌دهد که «الهام علی‌اُف رئیس جمهور و حزب آذربایجانِ نوینِ او»، از حساب‌های جعلی در \textenglish{\textbf{Facebook}} به عنوان بخشی از کمپین هدف قرار دادن روزنامه نگاران و صداهای مخالف استفاده کردند.
او می‌گوید که در یک دوره سه‌ماهه در سال 2019، «تقریباً 2.1 میلیون کامنت منفی و آزاردهنده در صفحات \textenglish{\textbf{Facebook}} رهبران مخالف و رسانه‌های مستقل منتشر کرد و آن‌ها را به خائن بودن متهم کرد».

ژانگ بیان می‌کند که \textenglish{\textbf{Facebook}} تهدیدهایی را که مستقیماً بر منافع ژئوپلیتیکی آمریکای شمالی و اروپای غربی تأثیر نمی‌گذارد، اولویت‌بندی می‌کند و جبران ناچیزی برای شهروندانی که تحت حاکمان خودکامه در کشورهایی مانند هندوراس و آذربایجان رنج می‌برند، باقی می‌گذارد.
مانند سخنان نفرت‌انگیزی که \textenglish{\textbf{Facebook}} در برمه مجاز کرد، سوء‌استفاده‌هایی که در کشورهای غیرغربی و فقیرتر انجام می‌شد به طور کلی نادیده‌گرفته‌شد.
کسانی که آزادی‌های کمتری دارند کمتر می‌گیرند.
\textenglish{\textbf{Facebook}} با این ادعا که سیاست آن‌ها اولویت‌بندی فوری‌ترین تهدیدها است، به مقابله پرداخته است، اما ژانگ می‌گوید که مشکل جدی است و \textenglish{\textbf{Facebook}} منابع کافی را برای مشکلی که آن‌ها در ایجاد آن نقش داشته‌اند، اختصاص نمی‌دهد.

او می‌گوید: «در سه سالی که در \textenglish{\textbf{Facebook}} گذرانده‌ام، چندین تلاش آشکار از سوی دولت‌های خارجی برای سوءاستفاده از پلتفرم ما در مقیاس وسیع برای گمراه کردن شهروندان خود پیدا کردم و در موارد متعدد باعث ایجاد اخبار بین‌المللی شدم».
او همچنین بیان می کند که \textenglish{\textbf{Facebook}} در مورد حذف آن‌ها برای فعالیت‌های غیراصیل هماهنگ شده شفاف نیست.

شرکت \textenglish{\textbf{Facebook}} به طور فزاینده‌ای نقش پیشرو در شکل‌دادن به سیاست، افکار عمومی، و بحث‌های مربوط به سیاست‌های عمومی (حتی تأثیرگذار بر نتایج انتخابات) در سراسر جهان، و نه فقط برای 2.8 میلیارد نفر از اعضای بشریت که مستقیماً از خدمات آن استفاده می‌کنند، ایفا می‌کند.
این به رهبری شرکت‌های شبکه‌های مجازی مانند \textenglish{\textbf{Facebook}} نقشی بزرگ و غیرقابل پاسخگویی در سیاست جهانی می‌دهد.
وونگ بیان می‌کند که این به برخی از کارکنان \textenglish{\textbf{Facebook}} اجازه می‌دهد تا «به‌عنوان نوعی شعبه قانون‌گذاری در تقریب \textenglish{\textbf{Facebook}} با یک دولت جهانی عمل کنند»، در حالی که «بقیه بیشتر شبیه یک هیئت دیپلماتیک خصوصی‌شده هستند، دفاتر کارکنان در سراسر جهان برای ارتباط با مشاغل محلی، جامعه مدنی.
گروه‌ها، تنظیم کننده‌های دولتی و سیاستمداران».
بیشتر این قدرت از الگوریتم‌های غیرشفاف ناشی می‌شود که محتوایی را که در پلتفرم‌هایشان ظاهر می‌شود (و مجاز به نمایش آن نیستند) تبلیغ، توصیه، فیلتر و واسطه می‌کنند و می‌توانند توسط بازیگران بد، دولت‌ها و خود شرکت‌ها دستکاری شوند.

«اداره‌ی فضای‌سایبری چین» اخیراً اقداماتی را برای تنظیم الگوریتم‌ها برای بهبود شفافیت و جلوگیری از برخی از این مشکلات انجام داده است (و تلاش‌های آن‌ها توسط تنظیم‌کننده‌ها در سراسر جهان مشاهده می‌شود).
این مقررات برای منع تبعیض توسط الگوریتم‌ها، جلوگیری از اعتیاد و استفاده بیش از حد، محافظت از مصرف‌کنندگان در برابر افزایش قیمت، و بهبود شفافیت و کنترل کاربر بر روی الگوریتم‌های توصیه و فیلتر برای تقویت «عدالت و عدالت اجتماعی» طراحی شده‌اند.
آن‌ها همچنین هدفشان ترویج یک "جهت گیری ارزشی اصلی"، "انتشار فعال انرژی مثبت" و ممنوعیت اطلاعات نادرست است که بر منافع ملی یا بازارهای اقتصادی چین تأثیر منفی می‌گذارد.
این تهدید بسیار واقعی وجود دارد که دولت-ملت‌ها از این الگوریتم‌ها برای سانسور دیدگاه‌های مخالف استفاده کنند و در عین حال تبلیغات خود را تقویت کنند، همراه با این احتمال که این الگوریتم‌ها و کسانی که آنها را کنترل می‌کنند امور جهانی را در قرن بیست و یکم شکل دهند!
\newline
\newline



{\setstretch{0.5}
\phantomsection
\section*{منشور اخلاق پزشکی نورنبرگ}
\label{sec:منشور اخلاق پزشکی نورنبرگ}
\addcontentsline{toc}{section}{منشور اخلاق پزشکی نورنبرگ}{\protect\numberline{}}
در «دادگاه جنایات جنگی نورنبرگ» که پس از جنگ جهانی دوم انجام شد، تقریباً 22 پزشک و دانشمند به دلیل انجام آزمایشات علمی غیرقانونی بر روی زندانیان، که بسیاری از آن‌ها یهودی بودند، در اردوگاه‌های کار اجباری نازی‌ها محاکمه شدند. این آزمایش‌ها، از جمله آزمایش‌هایی که روی کودکان یهودی انجام می‌شد، شامل شکنجه، کشتار دسته جمعی و اتانازی بود. این دادگاه که به عنوان "محاکمه پزشکان" شناخته می شود، از 25 اکتبر 1946 تا 20 اوت 1947 برگزار شد.
}

در نتیجه آزمایش پزشکان، استاندارد جدیدی ایجاد شد که براساس آن آزمایش‌های انسانی بر اساس اصول رضایت آگاهانه داوطلبانه افرادی که روی آن‌ها آزمایش می‌شوند، کنترل می‌شد و آزمایش‌ها به نفع جامعه به عنوان یک کل هدایت می‌شد.
این کتاب به یکی از مهمترین اسناد هدایت کننده اخلاق علمی در عصر مدرن تبدیل شده‌است.
این به هدایت اخلاق تحقیق و آزمایش در مورد موضوعات انسانی در سراسر جهان ادامه می‌دهد.
کدهای اخلاق تحقیق هنوز در مورد آزمایشات انجام شده توسط شرکت‌های خصوصی اعمال نمی‌شود.
\newpage



{\setstretch{0.5}
\phantomsection
\section*{تفسیر}
\label{sec:تفسیر}
\addcontentsline{toc}{section}{تفسیر}{\protect\numberline{}}


\phantomsection
\subsection*{اخلاق بودایی}
\label{subsec:اخلاق بودایی}
\addcontentsline{toc}{subsection}{اخلاق بودایی}{\protect\numberline{}}
\noindent \textbf{نوشته پیتر هرشوک}
\\\\
سیستم‌های هوش‌مصنوعی که در پیش‌بینی علایق، دوست نداشتن‌ها، احساسات، انتخاب‌ها و اعمال انسان مهارت دارند نیز می‌توانند آن‌ها را تولید کنند. در مورد کمبریج آنالیتیکا، هدف شرکتی اعلام شده آن شکل دادن به افکار عمومی و انتخاب با بهره‌برداری از ظرفیت سیستم‌های یادگیری‌ماشین برای تبدیل منابع معرفتی تولید شده توسط رسانه‌های اجتماعی، تجارت الکترونیک و جستجوی دیجیتال به قدرت هستی‌شناختی است. به صورت دیجیتالی فردی برای دستکاری اطلاعاتی.
}

قدردانی از خشم اخلاقی در «طرح تجاری» کمبریج آنالیتیکا سخت نیست.
همانطور که مطالعه موردی اشاره می‌کند، با این حال، هیچ زمینه‌ی انتخاب واقعاً خنثی وجود ندارد.
کل محتوای اینترنت نمی‌تواند به طور همزمان برای هیچ کاربری ارائه شود، و بنابراین ارزش ها و مقاصد لزوماً در معماری انتخابی اتصال دیجیتال وارد می‌شوند.
این نشان می‌دهد که سؤالات اخلاقی اساسی که باید پرسیده‌شود این است که کدام ارزش ها، چه کسانی و چرا انتخاب شده‌اند.

تابع هدف الگوریتم‌های کمبریج آنالیتیکا ساده و قابل‌فروش است: ایجاد رفتار رأی‌دهی مطابق با خواسته‌های مشتریانش.
سیستم اعتبار اجتماعی چین و سیاست‌ها و شیوه‌های گسترده‌تر اداره فضای سایبری این کشور، عملکرد هدفی ظاهراً مطلوب‌تر و ارزش‌آفرین‌تری را ارائه می‌کند (ترویج انصاف و عدالت اجتماعی).
ظاهراً، به نظر می‌رسد که ما با دو رویکرد کاملاً متفاوت برای شکل‌دهی الگوریتمی انتخاب‌ها و رفتار، و، اساساً، با دو سیستم به ظاهر متضاد حاکمیت اتصال روبرو هستیم.

یکی مبتنی بر منطق میانجی‌گری اجتماعی مبتنی بر انتخاب است که هم جلب توجه و هم استقلال تجربه‌شده را با تقویت محیطی الگوهای مبتنی بر فردیت اتصال دیجیتال به حداکثر می‌رساند (سیستمی که با رویکرد «بازار» آمریکا در حاکمیت داده‌ها تجسم یافته‌است که پیگیری منصفانه و رقابتی را امکان‌پذیر می‌سازد).
از یک جامعه ظاهراً خودسازمانده و پر جنب و جوش "چند صدایی".
دیگری مبتنی بر منطق مهندسی اجتماعی مبتنی بر کنترل سوگیری است که توسط سیستم اعتبار اجتماعی "مدیریتی" چین تجسم یافته است که پتانسیل‌های تعاونی و یکپارچگی رابطه‌ای را به حداکثر می‌رساند (سیستمی که حول دستکاری متمرکز تمرکز جمعیت و پویایی عمدی در پیگیری ترکیبی یک پایدار طراحی شده است.
جامعه "سمفونیک").

برخلاف ابزارگرایی بی‌سابقه‌ی کمبریج آنالیتیکا، تعهد اعلام‌شده چین به توسعه معماری انتخاب دیجیتال برای افزایش رفاه‌اجتماعی جذابیت قابل‌توجهی دارد.
اگر افراد به طور تقلیل‌ناپذیری رابطه‌ای فرض می‌شوند، اگر رفاه‌شخصی تابعی از رفاه اجتماعی در‌نظر گرفته‌شود، و اگر این مسئولیت دولت است که شرایط رفاه اجتماعی را تضمین کند، در این صورت می‌توان استدلال کرد که استفاده از ابزارهای الگوریتمی برای شکل‌دهی رفتار شهروندان و روابط مدنی.
مسئولیت اخلاقی دولت اگر بتوان معماری انتخابی را برای بهبود روابط انسان-انسان، انسان-جهان و انسان-تکنولوژی-جهان طراحی کرد، باید طراحی و اجرا شود.
این، قطعاً موضع حزب کمونیست چین است.

البته، اگر واحد اساسی تحلیل اخلاقی، فرد و انسان ایده‌آل مستقل باشد، سیستم اعتبار اجتماعی چین و تلاش‌های اداره فضای‌سایبری آن برای القای رفتار شهروندان و مصرف‌کنندگانی که دولت چین آن را مطلوب می‌داند، مهندسی اجتماعی اجباری است (نقض آشکار حقوق اطلاعاتی و ارتباطی با توجه به اینکه همین امر در مورد دستکاری‌های انتخاباتی کمبریج آنالیتیکا نیز صادق است، ممکن است تصور شود که بهترین و بدیهی ترین جایگزین این است که اطمینان حاصل شود که ترجیحات کاربر (و فقط ترجیحات کاربر) معماری انتخابی را شکل می‌دهند که با ادغام ارزش‌ها و تصمیمات آن‌ها به صورت بازگشتی در محاسبات سفارشی که در تنظیم تجربیات پیوندی آن‌ها نقش دارند).

این طرح اولیه‌ی الگوریتم‌های جستجو و توصیه است که در حال حاضر برای مثال توسط گوگل و آمازون استفاده می شود.
با توجه به جذب و ارضای خواسته‌ها و خواسته‌های فردی به عنوان ابعاد اولیه عملکرد هدف سیستم‌های یادگیری‌ماشین آن‌ها، یک معماری انتخابی در حال بهبود بازگشتی پدیدار می‌شود که برای پیش‌بینی دقیق‌تر و ارائه‌ی آنچه که مردم می‌خواهند (از نظر اخلاقی قابل ستایش است).
"سیستم‌هایی برای افزایش آزادی‌های شخصی در انتخاب".

آزادی انتخاب بدون شک بر نبود آن ارجح است.
اما آزادی انتخاب به تنهایی عامل ناقصی برای آزادی در مفهوم بودایی تحقق پویایی‌های رابطه‌ای است.
کارما شامل الگوهای چرخه‌ای درهم تنیدگی است که نتایج تجربی ارزش‌ها و مقاصد اعمال‌شده نیز به‌عنوان فرصت‌های ارادی عمل می‌کنند.
خطر رابطه‌ای از الگوریتم‌های جستجو و توصیه‌های خودبهبود این است که کاربران گروگان رفتارهای گذشته‌شان خواهند بود، زیرا معماری انتخاب شخصی‌شده‌شان آنقدر مؤثر می‌شود که همیشه «دقیقاً» چیزی را که به دنبال آن هستند (اخبار، سرگرمی‌ها، محصولات، پیدا می‌کنند).
خدمات و ارتباط اجتماعی طوری زندگی‌ها را خواهند ساخت که، در آن هرگز لازم نیست از اشتباهات درس بگیریم یا درگیر رفتار انطباقی باشیم.
تصحیح دوره هرگز ضروری یا مطلوب به نظر نمی‌رسد.

این به اندازه‌ی‌کافی ناراحت‌کننده است.
اما با توجه به ماهیت رابطه‌ای همه‌چیز، خطرات تکنولوژیکی بسیار عمیق‌تر می‌شوند.
در میان علل کشمکش، مشکل و رنج، بودیسم این باور را محوری می‌داند که هر یک از ما به طور مستقل وجود داریم و دارای یک "خود" واحد و ماندگار هستیم که می‌تواند مستقل از بدن وجود داشته‌باشد.
غیردوآلیسم رابطه‌ای (و نه تقلیلی) بودایی مستلزم این است که همه چیز را به‌طور قابل توجهی به هم وابسته بدانیم (ببینیم که هر چیز چگونه برای همه چیزها معنی دارد).
ذهن و بدن، پدیده‌ای و جسمانی، پیامدهای سازنده یکدیگر هستند.
آگاهی عبارت است از تمایز منسجم حضورهای محسوس و حسی یا تمایز منسجم ماده و آنچه مهم است.
به این معنا که توضیح این که چگونه پدیده‌های پدیدار از جسم فیزیکی یا چگونه انگیزه‌های انسانی از حرکات مولکولی عصبی ناشی می‌شوند، «مشکل سخت» وجود ندارد.

مغز عامل آگاهی نیست.
در عوض، روابط بین مغزها، بدن‌ها و محیط‌هایی که با آن‌ها و درون آن‌ها تکامل یافته‌اند، زیرساخت آگاهی را تشکیل می‌دهند.
آن‌ها نتیجه کاری هستند که آگاهی انجام می‌دهد (به طور منسجمی تفاوت‌ها را توضیح می‌دهد) به همان شکلی که زیرساخت‌های حمل و نقل نتیجه شیوه‌های حمل و نقل گذشته است که سپس به صورت بازگشتی شیوه‌های حمل و نقل بعدی را شکل می‌دهند.
اهمیت اخلاقی این موضوع این است که زیرساخت آگاهی انسان هم درون جمجمه‌ای و هم برون جمجمه‌ای است، هم شخصی و هم بین فردی و فراتر از بدن ما به محیط‌های طبیعی ما گسترش می‌یابد، اما همچنین محیط‌های اجتماعی، فرهنگی و تکنولوژیکی ما (از جمله اتصال دیجیتالی).

آزمایش میدانی که از طریق زیرساخت محاسباتی اتصال دیجیتال برای تأثیرگذاری بر انتخاب‌های انسان، احساسات و رفتار انجام می‌شود، مشابه قرار دادن الکترودها در زیرساخت عصبی مغز به منظور تولید تجربیات خارق‌العاده یا اعمال بدنی است.
چیزی که کمبریج آنالیتیکا، \textenglish{\textbf{Facebook}} و اداره فضای‌سایبری چین در حال آزمایش آن هستند، قرار دادن "الکترودهای" الگوریتمی در بافت‌همبند زیرساخت اجتماعی تجسم یافته و اجرا شده آگاهی مشترک انسان است (فرآیندی که به همان اندازه تهاجمی و از نظر اخلاقی مملو از درج است).
الکترودها به مغز آزمایش‌های انبوه در جذب دیجیتالی و بهره‌برداری از توجه انسان برای شکل‌دهی به احساسات، باورها، تصمیم‌گیری و اجتماعی‌سازی ارزشی خنثی نیستند و هرگز نمی‌توانند ارزشی داشته‌باشند.

اگر ارزش‌های انسانی رقیب به فناوری هوشمند تزریق شود، این تضادها را افزایش داده و عمیق‌تر می‌کند.
بداهه اخلاقی و فضیلت رابطه‌ای که برای حل این تعارض‌ها مورد نیاز است، طبق آیین بودا، به مشارکت در اعمالی بستگی دارد که اساسی‌ترین حقوق انسانی ما ـحق آزادی توجه) را تضمین می‌کند.
بدون آزادی توجه، آزادی قصد وجود نخواهد داشت، و بدون آزادی نیت، ما درگیر درهم تنیدگی‌های کارمایی گذشته خواهیم بود و بنابراین نمی‌توانیم با تغییر دادن آنچه که قصد داریم و برای آن چیزی که هستیم، تغییر دهیم برای یکی دیگر.
به عبارت دیگر، ما نمی‌توانیم در مهم‌ترین هنرهای بشری (هنر اخلاقی تصحیح مسؤولانه‌ی درس) شرکت کنیم.






